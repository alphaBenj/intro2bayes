{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayesian Statistics\n",
    "- Alternative to what is thought in schools\n",
    "- Became more usefull with recent advances in math and computation\n",
    "- Works well when data is limited\n",
    "- Applications vary from simple models to state of art machine learning, rocket science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Formal Definition\n",
    "$$P(\\theta\\mid X) = \\frac{P(X\\mid\\theta)P(\\theta)}{P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Formal Definition: Explanation\n",
    "\n",
    "$$P(\\theta\\mid X) = \\frac{P(X\\mid\\theta)P(\\theta)}{P(X)}$$\n",
    "\n",
    "|Probability      |   | Meaning                                    |  \n",
    "|----------------:|---|:-------------------------------------------|  \n",
    "|$P(\\theta\\mid X)$| = | Posterior                                  |     \n",
    "|$P(\\theta)$      | = | Prior                                      |  \n",
    "|$P(X\\mid\\theta)$ | = | Conditional Probability (Lieklihood)       |  \n",
    "|$P(X)$           | = | Marginal Probability(Normalizing Constant) |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Formal Definition: Better Explanation\n",
    "\n",
    "$$P(\\theta\\mid X) = \\frac{P(X\\mid\\theta)P(\\theta)}{P(X)}$$\n",
    "\n",
    "$P(\\theta\\mid X)$ = probability that theory $\\theta$ is correct **after** taking into account new data  \n",
    "$P(X\\mid\\theta)$ = probability of seeing this data we just saw assuming that theory $\\theta$ is correct  \n",
    "$P(\\theta)$ = probability that theory $\\theta$ is correct **before** we examine our new data  \n",
    "$P(X)$ = probability of seeing this data without assuming that theory $\\theta$ is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cookie Problem (from Think Bayes)\n",
    "\n",
    "There are two Bowl of cookies.  \n",
    "Bowl 1 has 50% Chocolate Chip, 50% Sugar Cookies.  \n",
    "Bowl 2 has 75% Chocolate Chip, 25% Sugar Cookies.\n",
    "\n",
    "You take a Chocoalte Chip cookie out of one of the bowls, what are the odds that you took it out of Bowl 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cookie Problem (from Think Bayes) cont.  \n",
    "\n",
    "__Prior__  \n",
    "\n",
    "|Value|Probability Notation|\n",
    "|---|-------|\n",
    "|50%| Bowl 1|\n",
    "|50%| Bowl 2|\n",
    "\n",
    "__Conditional Probalility__  \n",
    "\n",
    "|Value|Probability|\n",
    "|-----------|------------------|\n",
    "|50%|$P(Chocolate \\mid Bowl 1)$|\n",
    "|50%|$P(Vanila \\mid Bowl 1)$   |\n",
    "|75%|$P(Chocolate \\mid Bowl 2)$|\n",
    "|25%|$P(Vanila \\mid Bowl 2)$   |\n",
    "\n",
    "__Marginal Probabilty__  \n",
    "\n",
    "| Value | Probability Notation | Calculation                                                 |\n",
    "|------|----------------|:------------------------------------------------------- :|\n",
    "|62.5% | $P(Chocolate)$ | $P(Chocolate \\mid Bowl 1)P(Bowl 1) + P(Chocolate \\mid Bowl 2)P(Bowl 2)$ |\n",
    "|37.5% | $P(Vanila)   $ | $P(Vanila \\mid Bowl 1)P(Bowl 1) + P(Vanila \\mid Bowl 2)P(Bowl 2)$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Regession\n",
    " - Regression model just like normal linear regession\n",
    " - Predictions and coefficients are not point estimates they are probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notable Models\n",
    "- Naive Bayes\n",
    "- Bayesian Network \n",
    "- Bayesian Deep Neural Network\n",
    "- Kalman Filter\n",
    "- Bayesian Structural Time Series\n",
    "- Bayesian Model Averaging Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Notable Models: Naive Bayes\n",
    "- Simple model\n",
    "- Scalable\n",
    "- Frequently used as a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Network\n",
    "- Describes conditional probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Deek Neural Network\n",
    "- Full power of newural network\n",
    "- does not assume "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Kalman Filter\n",
    " - __powerfull__ model for estimation\n",
    " - Improves estimates of not trustworthy models\n",
    " - Does not trust bad(noisy) data\n",
    " - Keeps on updating estimates even if we don't have new data\n",
    " - Trusted by NASA in putting a man on the moon (Apollo 11 guidance computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Strutural Time Series\n",
    " - __Kalman Filter__ that doesn't just improve estimates it updates the model\n",
    " - Estimates with multiple versions of the model simultaniously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayesian Model Averaging Ensambles\n",
    " - Meta-model that leverages error estimates of multiple bayesian models\n",
    " - Per Tom Mitchell this will always be the best enambling technique\n",
    " \n",
    " Tom M. Mitchell, Machine Learning, 1997, pp. 175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Steps\n",
    "Free resources:\n",
    " - Think Bayes by Allen Downey (link)[http://greenteapress.com/wp/think-bayes/]\n",
    " - Bayesian Methods for Hackers (link)[https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers]\n",
    "\n",
    "Concepts to learn/review:\n",
    "- Go back to fundamentals(Probability theory)\n",
    "- More types of probability distributions, Beta, Gamma, Possion, Multivariate Gagussian. etc."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
